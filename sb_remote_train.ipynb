{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines_external_data import SBPPORemoteData\n",
    "import pickle\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import socket\n",
    "import sys\n",
    "from multiprocessing import Queue as queue\n",
    "import pickle\n",
    "import multiprocessing\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultipleWorker(object):\n",
    "    \"\"\"Handles multiple workers identified by IDs.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize with zero workers.\"\"\"\n",
    "        self.workers = set()\n",
    "        self.kwargs_queues = {}\n",
    "        self.return_queues = {}\n",
    "        self.worker_processes = {}\n",
    "        assert hasattr(self, '_process_fcn'), \"Please implement _process_fcn\"\n",
    "        self._process_init()\n",
    "        \n",
    "    def target_process(self, worker_id):\n",
    "        \"\"\"Process to run in each worker.\"\"\"\n",
    "        #print(\"Starting process\", worker_id)\n",
    "        while True:\n",
    "            kwargs = pickle.loads(self.kwargs_queues[worker_id].get())\n",
    "            try:\n",
    "                result = self._process_fcn(**kwargs, worker_id=worker_id)\n",
    "            except Exception as e:\n",
    "                result = (\"Exception\", traceback.format_exc())\n",
    "                pass\n",
    "            self.return_queues[worker_id].put(pickle.dumps(result))\n",
    "            \n",
    "    def _process_init(self):\n",
    "        \"\"\"Initialize client code.\"\"\"\n",
    "        pass\n",
    "            \n",
    "    def _process_fcn(self, **kwargs):\n",
    "        \"\"\"Process function, to be implemented.\"\"\"\n",
    "        #print(\"Called with:\", kwargs)\n",
    "        return str(kwargs)\n",
    "        \n",
    "    def new_worker(self, worker_id):\n",
    "        \"\"\"Create a worker with a given ID.\"\"\"\n",
    "        if worker_id in self.workers:\n",
    "            return\n",
    "        else:\n",
    "            self.workers.add(worker_id)\n",
    "            self.kwargs_queues[worker_id] = queue()\n",
    "            self.return_queues[worker_id] = queue()\n",
    "            self.worker_processes[worker_id] = multiprocessing.Process(target=self.target_process,\n",
    "                                                                       kwargs=dict(worker_id=worker_id))\n",
    "            self.worker_processes[worker_id].start()\n",
    "            \n",
    "    def process(self, worker_id, kwargs):\n",
    "        \"\"\"Process a request.\"\"\"\n",
    "        if worker_id not in self.workers:\n",
    "            print(\"Creating worker\", worker_id)\n",
    "            self.new_worker(worker_id)\n",
    "        self.kwargs_queues[worker_id].put(pickle.dumps(kwargs))\n",
    "        res = self.return_queues[worker_id].get()\n",
    "        return pickle.loads(res)\n",
    "    \n",
    "    def __del__(self):\n",
    "        \"\"\"Close all processes.\"\"\"\n",
    "        for p in self.worker_processes.values():\n",
    "            p.kill()\n",
    "            \n",
    "class MultiStepTrainer(object):\n",
    "    \"\"\"Train with stable baselines on external data, supporting multiple trainers.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.trainers = {}\n",
    "    def create(self, uid, config):\n",
    "        if uid in self.trainers:\n",
    "            print(\"Trainer %s already exists, doing nothing\" % uid)\n",
    "        else:\n",
    "            self.trainers[uid] = SBPPORemoteData(config=config)\n",
    "    def process(self, uid, rollouts, weights):\n",
    "        if uid not in self.trainers:\n",
    "            print(\"Error: trainer %s does not exist\" % uid)\n",
    "            return None\n",
    "        \n",
    "        self.trainers[uid].set_weights(weights)\n",
    "        info = self.trainers[uid].learn(rollouts)\n",
    "        new_weights = self.trainers[uid].get_weights()\n",
    "        return {'info': info, 'weights': new_weights}\n",
    "            \n",
    "class MultipleWorkerTrainer(MultipleWorker):\n",
    "    \"\"\"Train with multiple workers.\"\"\"\n",
    "    \n",
    "    def _process_init(self):\n",
    "        self.trainer = None\n",
    "    \n",
    "    def _process_fcn(self, uid, config, data_path, answer_path, worker_id):\n",
    "        if self.trainer is None:\n",
    "            self.trainer = MultiStepTrainer()\n",
    "        self.trainer.create(uid, config)\n",
    "        data = pickle.load(open(data_path, 'rb'))\n",
    "        rollouts = data['rollouts']\n",
    "        weights = data['weights']\n",
    "        \n",
    "        result = self.trainer.process(uid, rollouts, weights)\n",
    "        \n",
    "        pickle.dump(result, open(answer_path, 'wb'))\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--port N]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /home/sergei/.local/share/jupyter/runtime/kernel-4c365b2d-38a4-465f-9ade-8ae6738116b6.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "from asgiref.sync import async_to_sync\n",
    "from tornado import ioloop, web\n",
    "from jsonrpcserver import method, dispatch as dispatch, serve\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Launch the multiprocess stable baselines server.')\n",
    "parser.add_argument('--port', metavar='N', default=1234,\n",
    "                    help='port to listen on')\n",
    "\n",
    "\n",
    "# Server for DatabasePreferenceLearner\n",
    "class MainHandler(web.RequestHandler):\n",
    "    def post(self):\n",
    "        request = self.request.body.decode()\n",
    "        print(request)\n",
    "        response = dispatch(request)\n",
    "        print(response)\n",
    "        if response.wanted:\n",
    "            self.write(str(response))\n",
    "\n",
    "app = web.Application([(r\"/\", MainHandler)])\n",
    "trainer = None\n",
    "            \n",
    "def run_server(port=50001):\n",
    "    \"\"\"Run server.\"\"\"\n",
    "\n",
    "    print(\"Listening on port %d\" % port)\n",
    "\n",
    "    global trainer\n",
    "    trainer = MultipleWorkerTrainer()\n",
    "\n",
    "    @method\n",
    "    def process(*args, **kwargs):\n",
    "        global trainer\n",
    "        return trainer.process(*args, **kwargs)\n",
    "    serve(port=port)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = parser.parse_args()\n",
    "    run_server(port=8899)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening on port 50001\n",
      "Creating worker aba_policy_player_1\n",
      "Creating agent humanoid_blocker\n",
      "Reading agent XML from: /home/sergei/git/chai/multiagent-competition/gym_compete/new_envs/assets/humanoid_body.xml\n",
      "Creating agent humanoid\n",
      "Reading agent XML from: /home/sergei/git/chai/multiagent-competition/gym_compete/new_envs/assets/humanoid_body.xml\n",
      "Scene XML path: /home/sergei/git/chai/multiagent-competition/gym_compete/new_envs/assets/world_body.humanoid_body.humanoid_body.xml\n",
      "Created Scene with agents\n",
      "WARNING:tensorflow:From /home/sergei/miniconda3/envs/tf1/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/miniconda3/envs/tf1/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/miniconda3/envs/tf1/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/miniconda3/envs/tf1/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/miniconda3/envs/tf1/lib/python3.7/site-packages/stable_baselines/common/policies.py:116: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/miniconda3/envs/tf1/lib/python3.7/site-packages/stable_baselines/common/policies.py:116: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/miniconda3/envs/tf1/lib/python3.7/site-packages/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/miniconda3/envs/tf1/lib/python3.7/site-packages/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/git/chai/multiagent-competition/gym_compete/policy.py:66: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/git/chai/multiagent-competition/gym_compete/policy.py:66: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/git/chai/multiagent-competition/gym_compete/policy.py:21: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/git/chai/multiagent-competition/gym_compete/policy.py:21: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/git/chai/multiagent-competition/gym_compete/policy.py:38: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/git/chai/multiagent-competition/gym_compete/policy.py:38: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/miniconda3/envs/tf1/lib/python3.7/site-packages/stable_baselines/common/distributions.py:418: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/miniconda3/envs/tf1/lib/python3.7/site-packages/stable_baselines/common/distributions.py:418: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/miniconda3/envs/tf1/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:190: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/miniconda3/envs/tf1/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:190: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/miniconda3/envs/tf1/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:198: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/miniconda3/envs/tf1/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:198: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/miniconda3/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/miniconda3/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/miniconda3/envs/tf1/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:206: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/miniconda3/envs/tf1/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:206: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/miniconda3/envs/tf1/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:240: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/miniconda3/envs/tf1/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:240: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/miniconda3/envs/tf1/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:242: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/miniconda3/envs/tf1/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:242: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "| approxkl           | 0.06915925 |\n",
      "| clipfrac           | 0.52264327 |\n",
      "| explained_variance | -6.38      |\n",
      "| fps                | 1372       |\n",
      "| n_updates          | 1          |\n",
      "| policy_entropy     | 24.122137  |\n",
      "| policy_loss        | -0.1785963 |\n",
      "| serial_timesteps   | 628        |\n",
      "| time_elapsed       | 2.62e-05   |\n",
      "| total_timesteps    | 628        |\n",
      "| value_loss         | 28006.676  |\n",
      "-----------------------------------\n",
      "Creating worker aba_policy_player_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [07/Sep/2020 00:24:37] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating agent humanoid_blocker\n",
      "Reading agent XML from: /home/sergei/git/chai/multiagent-competition/gym_compete/new_envs/assets/humanoid_body.xml\n",
      "Creating agent humanoid\n",
      "Reading agent XML from: /home/sergei/git/chai/multiagent-competition/gym_compete/new_envs/assets/humanoid_body.xml\n",
      "Scene XML path: /home/sergei/git/chai/multiagent-competition/gym_compete/new_envs/assets/world_body.humanoid_body.humanoid_body.xml\n",
      "Created Scene with agents\n",
      "WARNING:tensorflow:From /home/sergei/miniconda3/envs/tf1/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/miniconda3/envs/tf1/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:191: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/miniconda3/envs/tf1/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/miniconda3/envs/tf1/lib/python3.7/site-packages/stable_baselines/common/tf_util.py:200: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/miniconda3/envs/tf1/lib/python3.7/site-packages/stable_baselines/common/policies.py:116: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/miniconda3/envs/tf1/lib/python3.7/site-packages/stable_baselines/common/policies.py:116: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/miniconda3/envs/tf1/lib/python3.7/site-packages/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/miniconda3/envs/tf1/lib/python3.7/site-packages/stable_baselines/common/input.py:25: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/git/chai/multiagent-competition/gym_compete/policy.py:66: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/git/chai/multiagent-competition/gym_compete/policy.py:66: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/git/chai/multiagent-competition/gym_compete/policy.py:21: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/git/chai/multiagent-competition/gym_compete/policy.py:21: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/git/chai/multiagent-competition/gym_compete/policy.py:38: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/git/chai/multiagent-competition/gym_compete/policy.py:38: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/miniconda3/envs/tf1/lib/python3.7/site-packages/stable_baselines/common/distributions.py:418: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/miniconda3/envs/tf1/lib/python3.7/site-packages/stable_baselines/common/distributions.py:418: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/miniconda3/envs/tf1/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:190: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/miniconda3/envs/tf1/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:190: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/miniconda3/envs/tf1/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:198: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/miniconda3/envs/tf1/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:198: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/miniconda3/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/miniconda3/envs/tf1/lib/python3.7/site-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/miniconda3/envs/tf1/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:206: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/miniconda3/envs/tf1/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:206: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/miniconda3/envs/tf1/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:240: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/miniconda3/envs/tf1/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:240: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/miniconda3/envs/tf1/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:242: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/sergei/miniconda3/envs/tf1/lib/python3.7/site-packages/stable_baselines/ppo2/ppo2.py:242: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| approxkl           | 0.13145663  |\n",
      "| clipfrac           | 0.6714968   |\n",
      "| explained_variance | -3.05       |\n",
      "| fps                | 1319        |\n",
      "| n_updates          | 1           |\n",
      "| policy_entropy     | 2.6566029   |\n",
      "| policy_loss        | -0.18494165 |\n",
      "| serial_timesteps   | 628         |\n",
      "| time_elapsed       | 2.79e-05    |\n",
      "| total_timesteps    | 628         |\n",
      "| value_loss         | 143010.02   |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [07/Sep/2020 00:24:39] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer 0 already exists, doing nothing\n",
      "-----------------------------------\n",
      "| approxkl           | 0.08314504 |\n",
      "| clipfrac           | 0.52       |\n",
      "| explained_variance | -6.45      |\n",
      "| fps                | 2261       |\n",
      "| n_updates          | 1          |\n",
      "| policy_entropy     | 24.11175   |\n",
      "| policy_loss        | -0.1782296 |\n",
      "| serial_timesteps   | 651        |\n",
      "| time_elapsed       | 1.41e-05   |\n",
      "| total_timesteps    | 651        |\n",
      "| value_loss         | 17387.547  |\n",
      "-----------------------------------\n",
      "Trainer 0 already exists, doing nothing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [07/Sep/2020 00:26:19] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| approxkl           | 0.1687577   |\n",
      "| clipfrac           | 0.65757287  |\n",
      "| explained_variance | -4.34       |\n",
      "| fps                | 2316        |\n",
      "| n_updates          | 1           |\n",
      "| policy_entropy     | 2.6631653   |\n",
      "| policy_loss        | -0.19491127 |\n",
      "| serial_timesteps   | 651         |\n",
      "| time_elapsed       | 1.53e-05    |\n",
      "| total_timesteps    | 651         |\n",
      "| value_loss         | 177388.5    |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [07/Sep/2020 00:26:19] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer 0 already exists, doing nothing\n",
      "------------------------------------\n",
      "| approxkl           | 0.09739331  |\n",
      "| clipfrac           | 0.5525522   |\n",
      "| explained_variance | -6.02       |\n",
      "| fps                | 2475        |\n",
      "| n_updates          | 1           |\n",
      "| policy_entropy     | 24.11979    |\n",
      "| policy_loss        | -0.17488614 |\n",
      "| serial_timesteps   | 623         |\n",
      "| time_elapsed       | 1.57e-05    |\n",
      "| total_timesteps    | 623         |\n",
      "| value_loss         | 12023.959   |\n",
      "------------------------------------\n",
      "Trainer 0 already exists, doing nothing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [07/Sep/2020 00:27:09] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| approxkl           | 0.21780328  |\n",
      "| clipfrac           | 0.72028893  |\n",
      "| explained_variance | -3.41       |\n",
      "| fps                | 2232        |\n",
      "| n_updates          | 1           |\n",
      "| policy_entropy     | 2.6520212   |\n",
      "| policy_loss        | -0.21072704 |\n",
      "| serial_timesteps   | 623         |\n",
      "| time_elapsed       | 1.5e-05     |\n",
      "| total_timesteps    | 623         |\n",
      "| value_loss         | 189153.66   |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [07/Sep/2020 00:27:09] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer 0 already exists, doing nothing\n",
      "-----------------------------------\n",
      "| approxkl           | 0.1215145  |\n",
      "| clipfrac           | 0.616332   |\n",
      "| explained_variance | -6.91      |\n",
      "| fps                | 2260       |\n",
      "| n_updates          | 1          |\n",
      "| policy_entropy     | 24.116104  |\n",
      "| policy_loss        | -0.1870755 |\n",
      "| serial_timesteps   | 518        |\n",
      "| time_elapsed       | 1.55e-05   |\n",
      "| total_timesteps    | 518        |\n",
      "| value_loss         | 17239.387  |\n",
      "-----------------------------------\n",
      "Trainer 0 already exists, doing nothing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [07/Sep/2020 00:27:52] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "| approxkl           | 0.28200954  |\n",
      "| clipfrac           | 0.73664093  |\n",
      "| explained_variance | -3.84       |\n",
      "| fps                | 2104        |\n",
      "| n_updates          | 1           |\n",
      "| policy_entropy     | 2.6567543   |\n",
      "| policy_loss        | -0.21154171 |\n",
      "| serial_timesteps   | 518         |\n",
      "| time_elapsed       | 1.88e-05    |\n",
      "| total_timesteps    | 518         |\n",
      "| value_loss         | 179554.92   |\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [07/Sep/2020 00:27:52] \"POST / HTTP/1.1\" 200 -\n",
      "Process Process-3:\n",
      "Process Process-2:\n",
      "Traceback (most recent call last):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e3f352de1d09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_server\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-b26fa58aa88e>\u001b[0m in \u001b[0;36mrun_server\u001b[0;34m(port)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mglobal\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mserve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf1/lib/python3.7/site-packages/jsonrpcserver/server.py\u001b[0m in \u001b[0;36mserve\u001b[0;34m(name, port)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" * Listening on port %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mhttpd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHTTPServer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRequestHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mhttpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserve_forever\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/tf1/lib/python3.7/socketserver.py\u001b[0m in \u001b[0;36mserve_forever\u001b[0;34m(self, poll_interval)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__shutdown_request\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m                     \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoll_interval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_request_noblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tf1/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/sergei/miniconda3/envs/tf1/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/sergei/miniconda3/envs/tf1/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/sergei/miniconda3/envs/tf1/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/sergei/miniconda3/envs/tf1/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-2-d8eddcf039a3>\", line 17, in target_process\n",
      "    kwargs = pickle.loads(self.kwargs_queues[worker_id].get())\n",
      "  File \"<ipython-input-2-d8eddcf039a3>\", line 17, in target_process\n",
      "    kwargs = pickle.loads(self.kwargs_queues[worker_id].get())\n",
      "  File \"/home/sergei/miniconda3/envs/tf1/lib/python3.7/multiprocessing/queues.py\", line 94, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/home/sergei/miniconda3/envs/tf1/lib/python3.7/multiprocessing/queues.py\", line 94, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/home/sergei/miniconda3/envs/tf1/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/sergei/miniconda3/envs/tf1/lib/python3.7/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/sergei/miniconda3/envs/tf1/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/sergei/miniconda3/envs/tf1/lib/python3.7/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/sergei/miniconda3/envs/tf1/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/sergei/miniconda3/envs/tf1/lib/python3.7/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "run_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open('rollout.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mst = MultiStepTrainer()\n",
    "config = data['config']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65071 50000\n",
      "Creating agent humanoid_blocker\n",
      "Reading agent XML from: /home/sergei/git/chai/multiagent-competition/gym_compete/new_envs/assets/humanoid_body.xml\n",
      "Creating agent humanoid\n",
      "Reading agent XML from: /home/sergei/git/chai/multiagent-competition/gym_compete/new_envs/assets/humanoid_body.xml\n",
      "Scene XML path: /home/sergei/git/chai/multiagent-competition/gym_compete/new_envs/assets/world_body.humanoid_body.humanoid_body.xml\n",
      "Created Scene with agents\n",
      "-------------------------------------\n",
      "| approxkl           | 0.022438252  |\n",
      "| clipfrac           | 0.14191274   |\n",
      "| explained_variance | -5.93        |\n",
      "| fps                | 4508         |\n",
      "| n_updates          | 1            |\n",
      "| policy_entropy     | 24.084276    |\n",
      "| policy_loss        | -0.054289613 |\n",
      "| serial_timesteps   | 65070        |\n",
      "| time_elapsed       | 3.12e-05     |\n",
      "| total_timesteps    | 65070        |\n",
      "| value_loss         | 4455.2646    |\n",
      "-------------------------------------\n",
      "65071 50000\n",
      "Creating agent humanoid_blocker\n",
      "Reading agent XML from: /home/sergei/git/chai/multiagent-competition/gym_compete/new_envs/assets/humanoid_body.xml\n",
      "Creating agent humanoid\n",
      "Reading agent XML from: /home/sergei/git/chai/multiagent-competition/gym_compete/new_envs/assets/humanoid_body.xml\n",
      "Scene XML path: /home/sergei/git/chai/multiagent-competition/gym_compete/new_envs/assets/world_body.humanoid_body.humanoid_body.xml\n",
      "Created Scene with agents\n",
      "------------------------------------\n",
      "| approxkl           | 0.028580695 |\n",
      "| clipfrac           | 0.1762929   |\n",
      "| explained_variance | -2.49       |\n",
      "| fps                | 4637        |\n",
      "| n_updates          | 1           |\n",
      "| policy_entropy     | 2.640088    |\n",
      "| policy_loss        | -0.05860268 |\n",
      "| serial_timesteps   | 65070       |\n",
      "| time_elapsed       | 1.93e-05    |\n",
      "| total_timesteps    | 65070       |\n",
      "| value_loss         | 67758.81    |\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "new_weights = {}\n",
    "for player in data['policies'].keys():\n",
    "    uid = str(data['uid']) + '/' + player\n",
    "    weights = data['weights_dict'][player]\n",
    "    rollout = data['samples'][player]\n",
    "    print(len(rollout['t']), config['train_batch_size'])\n",
    "    mst.create(uid=uid, config=config)\n",
    "    new_weights[player] = mst.process(uid=uid, rollouts=rollout, weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "459M\trollout.pkl\n"
     ]
    }
   ],
   "source": [
    "!du -s --si rollout.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
